# -*- coding: utf-8 -*-
"""
å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ  v5 (AI APIã‚¼ãƒ­ / ç„¡æ–™é‹ç”¨æƒ³å®š)
- RSSã®ã¿ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ï¼ˆå½“æ—¥â†’7æ—¥â†’30æ—¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
- å¿…ãš1éŠ˜æŸ„1æœ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é…ä¿¡ï¼ˆãªã‘ã‚Œã°ã€Œè¦‹ã¤ã‹ã‚‰ãªã„ã€ã§ã¯ãªãã€30æ—¥ã¾ã§æ¢ã—åˆ‡ã‚‹ï¼‰
- ä¸­å›½èªã‚¿ã‚¤ãƒˆãƒ«ã®ä¸Šã«ã€æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆç°¡æ˜“è¾æ›¸å¤‰æ›ï¼‰ã‚’ä»˜ä¸
- URLã¯æœ¬æ–‡ã«ãƒ™ã‚¿è²¼ã‚Šã—ãªã„ï¼ˆè¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ï¼‰
- SendGridã§ãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆSENDGRID_API_KEY / SENDGRID_FROM / SENDGRID_TOï¼‰

ç’°å¢ƒå¤‰æ•°ï¼ˆGitHub Actions Secretsæ¨å¥¨ï¼‰:
- SENDGRID_API_KEY
- SENDGRID_FROM
- SENDGRID_TO
"""

import os
import re
import json
import time
import hashlib
from datetime import datetime, timedelta
from urllib.parse import urlparse

import requests
import feedparser
import pytz
from dateutil import parser as date_parser
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail

# ============================================================
# è¨­å®š
# ============================================================

TZ = pytz.timezone("Asia/Taipei")

# RSSã‚½ãƒ¼ã‚¹ï¼ˆç„¡æ–™ãƒ»æ¯”è¼ƒçš„å®‰å®šï¼‰
# â€»å¿…è¦ãªã‚‰ã“ã“ã«è¿½åŠ ã§ãã¾ã™ï¼ˆã‚³ãƒ¼ãƒ‰ã‚’å£Šã—ã«ãã„æ§‹é€ ã«ã—ã¦ã‚ã‚Šã¾ã™ï¼‰
RSS_FEEDS = [
    # Yahooå¥‡æ‘©è‚¡å¸‚ï¼ˆæ ªå¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
    "https://tw.stock.yahoo.com/rss",
    # ç¶“æ¿Ÿæ—¥å ± (UDN) - è²¡ç¶“
    "https://money.udn.com/rssfeed/news/1001/5591?ch=money",
    # å·¥å•†æ™‚å ± - è²¡ç¶“ï¼ˆâ€»ãƒ•ã‚£ãƒ¼ãƒ‰ãŒå¤‰ã‚ã‚‹å ´åˆã‚ã‚Šï¼‰
    "https://ctee.com.tw/feed",
    # MoneyDJ - å°è‚¡ï¼ˆâ€»ãƒ•ã‚£ãƒ¼ãƒ‰ãŒå¤‰ã‚ã‚‹å ´åˆã‚ã‚Šï¼‰
    "https://www.moneydj.com/kmdj/rss/rssfeed.aspx?a=mb010000",
]

# åé›†ä¸Šé™ï¼ˆå…¨ãƒ•ã‚£ãƒ¼ãƒ‰åˆè¨ˆï¼‰
MAX_ENTRIES_TOTAL = 800

# ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆå½“æ—¥â†’7æ—¥â†’30æ—¥ï¼‰
WINDOWS = [
    ("today", 1),
    ("weekly", 7),
    ("monthly", 30),
]

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š
HTTP_TIMEOUT = 12
HTTP_RETRIES = 2

# ============================================================
# æ—¥æœ¬èªåŒ–ï¼ˆç„¡æ–™ï¼†å®‰å®šã®ãŸã‚ã€Œç°¡æ˜“è¾æ›¸ï¼‹æ•´å½¢ã€ï¼‰
# ============================================================

CN2JP_DICT = [
    # ä¼šç¤¾/å¸‚å ´/é‡‘è
    (r"å°ç©é›»", "TSMCï¼ˆå°ç©é›»ï¼‰"),
    (r"å°è‚¡", "å°æ¹¾æ ª"),
    (r"ç¾è‚¡", "ç±³å›½æ ª"),
    (r"è²¡å ±", "æ±ºç®—"),
    (r"ç‡Ÿæ”¶", "å£²ä¸Š"),
    (r"ç²åˆ©", "åˆ©ç›Š"),
    (r"æ¯›åˆ©ç‡", "ç²—åˆ©ç›Šç‡"),
    (r"æ·¨åˆ©", "ç´”åˆ©ç›Š"),
    (r"æ³•èªªæœƒ", "æ±ºç®—èª¬æ˜ä¼š"),
    (r"è‚¡åƒ¹", "æ ªä¾¡"),
    (r"è‚¡åƒ¹èµ°å‹¢", "æ ªä¾¡æ¨ç§»"),
    (r"ç›®æ¨™åƒ¹", "ç›®æ¨™æ ªä¾¡"),
    (r"ä¸Šæ¼²", "ä¸Šæ˜‡"),
    (r"ä¸‹è·Œ", "ä¸‹è½"),
    (r"å¤§è·Œ", "æ€¥è½"),
    (r"å¤§æ¼²", "æ€¥é¨°"),
    (r"åˆ©å¤š", "å¥½ææ–™"),
    (r"åˆ©ç©º", "æ‚ªææ–™"),
    (r"å¤–è³‡", "æµ·å¤–æŠ•è³‡å®¶"),
    (r"æŠ•ä¿¡", "æŠ•è³‡ä¿¡è¨—"),
    (r"è‡ªç‡Ÿå•†", "è‡ªå·±å£²è²·"),
    (r"è²·è¶…", "è²·ã„è¶Šã—"),
    (r"è³£è¶…", "å£²ã‚Šè¶Šã—"),
    (r"ETF", "ETF"),
    (r"AI", "AI"),
    (r"ä¼ºæœå™¨", "ã‚µãƒ¼ãƒãƒ¼"),
    (r"ä¾›æ‡‰éˆ", "ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³"),
    (r"åŠå°é«”", "åŠå°ä½“"),
    (r"è¨˜æ†¶é«”", "ãƒ¡ãƒ¢ãƒª"),
    (r"DRAM", "DRAM"),
    (r"NAND", "NAND"),
    (r"ç­†é›»", "ãƒãƒ¼ãƒˆPC"),
    (r"è³‡æ–™ä¸­å¿ƒ", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼"),
    (r"é›²ç«¯", "ã‚¯ãƒ©ã‚¦ãƒ‰"),
    (r"è¨‚å–®", "å—æ³¨"),
    (r"å‡ºè²¨", "å‡ºè·"),
    (r"ç”¢èƒ½", "ç”Ÿç”£èƒ½åŠ›"),
    (r"æ“´ç”¢", "å¢—ç”£"),
    (r"æ¸›ç”¢", "æ¸›ç”£"),
    (r"ç¾å…ƒ", "ç±³ãƒ‰ãƒ«"),
    (r"æ–°å°å¹£", "å°æ¹¾ãƒ‰ãƒ«"),
    # ã‚ˆãã‚ã‚‹è¨˜å·/è¡¨è¨˜
    (r"ã€", "["),
    (r"ã€‘", "]"),
]

def cn_title_to_jp(title_cn: str) -> str:
    """ç„¡æ–™ã§å®‰å®šã•ã›ã‚‹ãŸã‚ã€ç¿»è¨³ã§ã¯ãªãâ€œæ—¥æœ¬èªåŒ–ï¼ˆç½®æ›ï¼‹æ•´å½¢ï¼‰â€ã«ç•™ã‚ã‚‹"""
    if not title_cn:
        return ""
    t = title_cn.strip()
    for pat, rep in CN2JP_DICT:
        t = re.sub(pat, rep, t)
    # ä½™è¨ˆãªã‚¹ãƒšãƒ¼ã‚¹æ•´å½¢
    t = re.sub(r"\s+", " ", t).strip()
    # ãã‚Œã§ã‚‚ä¸­å›½èªãŒå¼·ã„å ´åˆã¯é ­ã«ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹
    # ï¼ˆå®Œå…¨ç¿»è¨³ã¯ã—ãªã„ï¼‰
    return f"ï¼ˆæ—¥æœ¬èªè¦ç´„ï¼‰{t}"

# ============================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================

def now_taipei() -> datetime:
    return datetime.now(TZ)

def normalize_url(url: str) -> str:
    if not url:
        return ""
    return url.strip()

def safe_domain(url: str) -> str:
    try:
        return urlparse(url).netloc or ""
    except Exception:
        return ""

def hash_key(*parts: str) -> str:
    raw = "||".join([p or "" for p in parts])
    return hashlib.sha256(raw.encode("utf-8")).hexdigest()[:16]

def parse_entry_datetime(entry) -> datetime | None:
    # feedparserã¯entry.published_parsed / updated_parsed ç­‰ã‚’æŒã¤ã“ã¨ãŒå¤šã„
    for key in ["published", "updated", "created"]:
        if hasattr(entry, key):
            try:
                dt = date_parser.parse(getattr(entry, key))
                if dt.tzinfo is None:
                    dt = TZ.localize(dt)
                else:
                    dt = dt.astimezone(TZ)
                return dt
            except Exception:
                pass
    # structured time
    for key in ["published_parsed", "updated_parsed"]:
        if hasattr(entry, key):
            try:
                st = getattr(entry, key)
                if st:
                    dt = datetime(*st[:6], tzinfo=pytz.utc).astimezone(TZ)
                    return dt
            except Exception:
                pass
    return None

def http_get(url: str) -> str:
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; TaiwanStockNewsBot/1.0; +https://github.com/)",
        "Accept": "application/rss+xml, application/xml;q=0.9, */*;q=0.8",
    }
    last_err = None
    for _ in range(HTTP_RETRIES + 1):
        try:
            r = requests.get(url, headers=headers, timeout=HTTP_TIMEOUT, allow_redirects=True)
            r.raise_for_status()
            return r.text
        except Exception as e:
            last_err = e
            time.sleep(0.8)
    raise RuntimeError(f"fetch failed: {url} / {last_err}")

def load_stocks() -> list[dict]:
    """
    stocks.json ä¾‹:
    [
      {"name":"å°ç©é›»","code":"2330","keywords":["å°ç©é›»","TSMC","2330"]},
      ...
    ]
    """
    # å„ªå…ˆï¼šåŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®stocks.json
    here = os.path.dirname(os.path.abspath(__file__))
    path = os.path.join(here, "stocks.json")

    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list) and data:
                return data

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰
    return [
        {"name": "å°ç©é›»", "code": "2330", "keywords": ["å°ç©é›»", "TSMC", "2330"]},
        {"name": "å‰µè¦‹", "code": "2451", "keywords": ["å‰µè¦‹", "Transcend", "2451"]},
        {"name": "å®‡ç»", "code": "8271", "keywords": ["å®‡ç»", "Apacer", "8271"]},
        {"name": "å»£é”", "code": "2382", "keywords": ["å»£é”", "Quanta", "2382"]},
    ]

def collect_rss_entries() -> list[dict]:
    """
    RSSå…¨ä½“ã‹ã‚‰è¨˜äº‹å€™è£œã‚’é›†ã‚ã‚‹ã€‚
    è¿”ã‚Šå€¤: [{"title":..., "link":..., "dt":..., "source":...}, ...]
    """
    out = []
    for feed_url in RSS_FEEDS:
        try:
            xml = http_get(feed_url)
            parsed = feedparser.parse(xml)
            for e in parsed.entries[:200]:
                title = (getattr(e, "title", "") or "").strip()
                link = normalize_url(getattr(e, "link", "") or "")
                dt = parse_entry_datetime(e)
                if not title or not link:
                    continue
                out.append({
                    "title": title,
                    "link": link,
                    "dt": dt,  # Noneã‚ã‚Š
                    "source": safe_domain(feed_url) or safe_domain(link) or "rss",
                })
        except Exception as ex:
            print(f"âš ï¸ RSSå–å¾—å¤±æ•—: {feed_url} / {ex}", flush=True)

    # é‡è¤‡é™¤å¤–ï¼ˆtitle+linkï¼‰
    seen = set()
    dedup = []
    for item in out:
        k = hash_key(item["title"], item["link"])
        if k in seen:
            continue
        seen.add(k)
        dedup.append(item)

    # æ–°ã—ã„é †ï¼ˆdtãŒNoneã¯æœ€å¾Œï¼‰
    def sort_key(x):
        return x["dt"] if x["dt"] else datetime(1970, 1, 1, tzinfo=TZ)
    dedup.sort(key=sort_key, reverse=True)

    # ä¸Šé™
    return dedup[:MAX_ENTRIES_TOTAL]

def within_days(dt: datetime | None, days: int) -> bool:
    if dt is None:
        # æ—¥ä»˜ãŒå–ã‚Œãªã„RSSã‚‚ã‚ã‚‹ãŸã‚ã€é™¤å¤–ã—ãªã„ï¼ˆãŸã ã—å„ªå…ˆåº¦ã¯ä¸‹ãŒã‚‹ï¼‰
        return True
    return dt >= (now_taipei() - timedelta(days=days))

def match_stock(item: dict, stock: dict) -> bool:
    title = (item.get("title") or "")
    # keywordä¸€è‡´ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã ã‘ï¼‰
    for kw in stock.get("keywords", []):
        if kw and kw in title:
            return True
    return False

def pick_best_news_for_stock(entries: list[dict], stock: dict) -> dict | None:
    """
    todayâ†’weeklyâ†’monthly ã®é †ã§æ¢ç´¢ã€‚
    ãã®ä¸­ã§æœ€ã‚‚æ–°ã—ã„ã‚‚ã®ã‚’æ¡ç”¨ã€‚
    """
    for label, days in WINDOWS:
        candidates = [it for it in entries if within_days(it["dt"], days) and match_stock(it, stock)]
        if candidates:
            # dtãŒNoneã®å ´åˆã¯æœ«å°¾ã«å›ã™
            candidates.sort(
                key=lambda x: x["dt"] if x["dt"] else datetime(1970, 1, 1, tzinfo=TZ),
                reverse=True
            )
            best = candidates[0].copy()
            best["bucket"] = label
            return best
    return None

def investment_helper_block() -> list[str]:
    # å›ºå®šã§æ¯å›ä»˜ã‘ã‚‹ï¼ˆè³ªä¿è¨¼ï¼‰
    return [
        "å¸‚å ´ã¯æ§˜å­è¦‹ãƒ•ã‚§ãƒ¼ã‚º",
        "çŸ­æœŸã¯ææ–™ãƒ»åå¿œã‚’ç¢ºèª",
        "ä¸­é•·æœŸã¯æŠ¼ã—ç›®ç›£è¦–",
    ]

def build_email_html(results: list[dict]) -> str:
    sent_at = now_taipei().strftime("%Y-%m-%d %H:%M")

    # ä»¥å‰ã®ã€Œã‚«ãƒ¼ãƒ‰å‹ã€å¯„ã›ï¼ˆã‚·ãƒ³ãƒ—ãƒ«HTMLï¼‰
    def card(title: str, body_html: str) -> str:
        return f"""
        <div style="border:1px solid #2b2b2b;border-radius:12px;padding:14px;margin:14px 0;background:#111;">
          <div style="font-size:18px;font-weight:700;margin-bottom:10px;color:#fff;">{title}</div>
          <div style="font-size:14px;line-height:1.65;color:#d6d6d6;">{body_html}</div>
        </div>
        """

    cards = []

    header = f"""
    <div style="font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,'Noto Sans JP','Hiragino Kaku Gothic ProN','Yu Gothic',sans-serif;background:#0b0b0b;color:#fff;padding:18px;">
      <div style="font-size:34px;font-weight:800;margin:0 0 6px 0;">ğŸ“ˆ å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡</div>
      <div style="color:#cfcfcf;font-size:14px;">é…ä¿¡æ—¥æ™‚ï¼š{sent_at}</div>
      <hr style="border:0;border-top:1px solid #2b2b2b;margin:14px 0;">
    """

    for r in results:
        stock_name = r["stock"]["name"]
        stock_code = r["stock"]["code"]
        news = r.get("news")

        if news:
            title_cn = news["title"]
            title_jp = cn_title_to_jp(title_cn)
            link = news["link"]
            source = news.get("source", "rss")
            dt = news.get("dt")
            dt_str = dt.strftime("%Y-%m-%d %H:%M") if dt else "æ—¥æ™‚ä¸æ˜"
            bucket = news.get("bucket", "today")

            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒªãƒ³ã‚¯åŒ–ï¼ˆURLã®ãƒ™ã‚¿è²¼ã‚Šç¦æ­¢ï¼‰
            # 2è¡Œæ§‹æˆï¼šæ—¥æœ¬èªï¼ˆä¸Šï¼‰â†’ä¸­å›½èªï¼ˆä¸‹ï¼‰
            body = f"""
            <div style="margin-bottom:10px;">
              <div style="font-weight:700;color:#9fd1ff;margin-bottom:4px;">
                <a href="{link}" style="color:#7db7ff;text-decoration:none;">{title_jp}</a>
              </div>
              <div style="color:#b8b8b8;">
                <a href="{link}" style="color:#7db7ff;text-decoration:none;">{title_cn}</a>
              </div>
              <div style="color:#8a8a8a;font-size:12px;margin-top:6px;">
                åˆ†é¡ï¼š{bucket} / å‡ºå…¸ï¼š{source} / æ—¥æ™‚ï¼š{dt_str}
              </div>
            </div>
            """
        else:
            # ã€Œçµ¶å¯¾1æœ¬ã€ãŒè¦æ±‚ãªã®ã§ã€ã“ã“ã¯åŸºæœ¬åˆ°é”ã—ãªã„æƒ³å®šã€‚
            body = f"""
            <div style="color:#ffb3b3;font-weight:700;margin-bottom:8px;">âš ï¸ 30æ—¥ä»¥å†…ã§ã‚‚è©²å½“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚</div>
            <div style="color:#b8b8b8;">æ¤œç´¢æ¡ä»¶ï¼ˆéŠ˜æŸ„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰ã‚’è¦è¦‹ç›´ã—ã€‚</div>
            """

        helper = investment_helper_block()
        helper_html = "<ul style='margin:8px 0 0 18px;'>" + "".join([f"<li>{h}</li>" for h in helper]) + "</ul>"

        body += f"""
        <div style="margin-top:12px;padding-top:10px;border-top:1px solid #2b2b2b;">
          <div style="font-weight:800;color:#b6ffcc;">ğŸ“Š æŠ•è³‡åˆ¤æ–­è£œåŠ©ï¼ˆæ ªä¾¡ãƒ•ã‚§ãƒ¼ã‚ºæ•´ç†ï¼‰</div>
          {helper_html}
        </div>
        """

        cards.append(card(f"{stock_name}ï¼ˆ{stock_code}ï¼‰", body))

    footer = """
      <hr style="border:0;border-top:1px solid #2b2b2b;margin:18px 0 10px;">
      <div style="color:#8a8a8a;font-size:12px;line-height:1.6;">
        â€»æœ¬ãƒ¡ãƒ¼ãƒ«ã¯RSSæƒ…å ±ã‚’ã‚‚ã¨ã«è‡ªå‹•ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚æŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
      </div>
    </div>
    """

    return header + "\n".join(cards) + footer

def send_email(html: str) -> None:
    api_key = os.environ.get("SENDGRID_API_KEY", "").strip()
    mail_from = os.environ.get("SENDGRID_FROM", "").strip()
    mail_to = os.environ.get("SENDGRID_TO", "").strip()

    if not api_key or not mail_from or not mail_to:
        print("âŒ SendGrid ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆSENDGRID_API_KEY / SENDGRID_FROM / SENDGRID_TOï¼‰", flush=True)
        return

    subject = "ğŸ“ˆ å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡"
    message = Mail(
        from_email=mail_from,
        to_emails=mail_to,
        subject=subject,
        html_content=html
    )

    try:
        sg = SendGridAPIClient(api_key)
        resp = sg.send(message)
        print(f"âœ… ãƒ¡ãƒ¼ãƒ«é€ä¿¡æˆåŠŸ (status={resp.status_code})", flush=True)
    except Exception as e:
        print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¤±æ•—: {e}", flush=True)

def main():
    print("=" * 60)
    print("å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ  v5ï¼ˆAI APIã‚¼ãƒ­ / RSSé‹ç”¨ï¼‰")
    print("=" * 60, flush=True)

    stocks = load_stocks()
    print(f"éŠ˜æŸ„æ•°: {len(stocks)}", flush=True)

    print("ğŸ“° RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ä¸­...", flush=True)
    entries = collect_rss_entries()
    print(f"âœ… åé›†å®Œäº†: {len(entries)}ä»¶ï¼ˆé‡è¤‡é™¤å¤–å¾Œï¼‰", flush=True)

    results = []
    for s in stocks:
        print("-" * 60)
        print(f"ğŸ“Š {s['name']}ï¼ˆ{s['code']}ï¼‰", flush=True)
        news = pick_best_news_for_stock(entries, s)

        # ã€Œå¿…ãš1éŠ˜æŸ„1æœ¬ã€ã‚’æœ€å„ªå…ˆï¼š30æ—¥ã§ã‚‚å–ã‚Œãªã„å ´åˆã¯â€œã‚¿ã‚¤ãƒˆãƒ«æœªç¢ºå®šã®ä»£æ›¿â€ã‚’ä½œã‚‹
        if not news:
            # ä»£æ›¿ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç„¡ã—ã§ã‚‚ã€ç›´è¿‘ã®â€œå°æ¹¾æ ªé–¢é€£ã£ã½ã„â€ã‚’æ‹¾ã†ï¼ˆæœ€å¾Œã®å®‰å…¨ç¶²ï¼‰
            # ã“ã“ã§0æœ¬ã®ã¾ã¾é€ã‚‹ã®ã‚’é˜²ã
            fallback = None
            for it in entries:
                if within_days(it["dt"], 30):
                    # å°æ¹¾æ ª/åŠå°ä½“/ã‚µãƒ¼ãƒãƒ¼/AIãªã©ä¸€èˆ¬ãƒ¯ãƒ¼ãƒ‰ã§æ‹¾ã†
                    if re.search(r"(å°è‚¡|åŠå°é«”|ä¼ºæœå™¨|AI|è²¡å ±|ç‡Ÿæ”¶|å¤–è³‡|ETF|å°ç©é›»|TSMC)", it["title"]):
                        fallback = it.copy()
                        fallback["bucket"] = "monthly"
                        break
            news = fallback

        if news:
            print(f"âœ… æ¡ç”¨: {news.get('bucket','?')} / {news['title']}", flush=True)
        else:
            print("âš ï¸ æ¡ç”¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—ï¼ˆæ¥µã‚ã¦ç¨€ï¼‰", flush=True)

        results.append({"stock": s, "news": news})

    html = build_email_html(results)
    send_email(html)

if __name__ == "__main__":
    main()
