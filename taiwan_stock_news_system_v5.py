#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGeminiç‰ˆ / ç„¡æ–™æ å‰æ / å®‰å®š80ç‚¹ï¼‰
è¦ä»¶:
- å„éŠ˜æŸ„ æœ€ä½1æœ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¿è¨¼ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã§ã‚‚å€™è£œã‹ã‚‰å¼·åˆ¶æ¡ç”¨ï¼‰
- today / weekly / monthly ã®åˆ†é¡ï¼ˆæ¤œç´¢ç¯„å›²ã‚’åºƒã’ã‚‹ï¼‰
- ä¸­å›½èªã‚¿ã‚¤ãƒˆãƒ« + æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¸Šã«æ—¥æœ¬èªï¼‰
- URLã¯æœ¬æ–‡ã«ç”ŸURLã‚’å‡ºã•ãšã€ã‚¿ã‚¤ãƒˆãƒ«ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯
- é‡è¤‡ã¯ã€ŒåŒä¸€URLã€ã€Œä¼¼ãŸã‚¿ã‚¤ãƒˆãƒ«ã€ã‚’æŠ‘åˆ¶
- Geminiã¯ã€Œ1éŠ˜æŸ„1å›ã€ã ã‘ä½¿ç”¨ï¼ˆç¿»è¨³+è¦ç‚¹+æœ€é‡è¦1æœ¬é¸æŠï¼‰
- Google Cloud Consoleï¼ˆèª²é‡‘ï¼‰ä¸è¦ï¼šGEMINI_API_KEY ã®ã¿ä½¿ç”¨
"""

VERSION = "v5.2-gemini-free-stable-20260128"

import os
import re
import json
import time
import hashlib
import requests
import feedparser
from datetime import datetime, timedelta
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
from concurrent.futures import ThreadPoolExecutor, as_completed

import pytz
from dateutil import parser as date_parser

from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail

# Gemini SDK (Google GenAI SDK)
# pip install google-genai
from google import genai  # type: ignore


TW_TZ = pytz.timezone("Asia/Taipei")

# ==========================
# ç’°å¢ƒå¤‰æ•°ï¼ˆå¿…é ˆï¼‰
# ==========================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
SENDGRID_API_KEY = os.getenv("SENDGRID_API_KEY", "").strip()

EMAIL_FROM = os.getenv("EMAIL_FROM", "").strip()  # é€ä¿¡å…ƒï¼ˆSendGridã§èªè¨¼æ¸ˆã¿ãŒæ¨å¥¨ï¼‰
EMAIL_TO = os.getenv("EMAIL_TO", "").strip()      # é€ä¿¡å…ˆï¼ˆè‡ªåˆ†ã®Gmailãªã©ï¼‰

# ä»»æ„: è¿½åŠ ã®é€ä¿¡å…ˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
EMAIL_TO_CC = os.getenv("EMAIL_TO_CC", "").strip()

# Geminiãƒ¢ãƒ‡ãƒ«ï¼ˆç„¡æ–™æ ã§ä½¿ã„ã‚„ã™ã„è»½é‡ç³»ï¼‰
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-flash").strip()

# ==========================
# éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ==========================
def load_stocks():
    """
    åŒä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® stocks.json ã‚’èª­ã‚€ã€‚
    å½¢å¼:
    { "stocks": { "2330": {"name":"å°ç©é›»","business_type":"..."}, ... } }
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    path = os.path.join(base_dir, "stocks.json")
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("stocks", {})
    except Exception as e:
        print(f"âŒ stocks.json èª­ã¿è¾¼ã¿å¤±æ•—: {e}", flush=True)
        return {}

STOCKS = load_stocks()


# ==========================
# RSSãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆå¿…è¦ãªã‚‰ã“ã“ã§å¢—ã‚„ã›ã‚‹ï¼‰
# ==========================
RSS_FEEDS = [
    # --- stock direct ---
    "https://news.google.com/rss/search?q=å°ç©é›»+OR+TSMC&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=TSMC&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=TSMC&hl=ja&gl=JP&ceid=JP:ja",

    "https://news.google.com/rss/search?q=å‰µè¦‹+OR+Transcend&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=å‰µè¦‹+OR+Transcend&hl=ja&gl=JP&ceid=JP:ja",

    "https://news.google.com/rss/search?q=å®‡ç»+OR+Apacer&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=Apacer&hl=en-US&gl=US&ceid=US:en",

    "https://news.google.com/rss/search?q=å»£é”+OR+Quanta&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=Quanta+Computer&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=å»£é”+OR+Quanta&hl=ja&gl=JP&ceid=JP:ja",

    # --- driver queries ---
    "https://news.google.com/rss/search?q=AIä¼ºæœå™¨&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=NVIDIA&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=GB200&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=HBM&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=DRAMåƒ¹æ ¼&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=åŠå°é«”&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=ODM&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",

    # --- earnings/event ---
    "https://news.google.com/rss/search?q=å°ç©é›»+ç‡Ÿæ”¶&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=å‰µè¦‹+ç‡Ÿæ”¶&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=å®‡ç»+ç‡Ÿæ”¶&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    "https://news.google.com/rss/search?q=å»£é”+ç‡Ÿæ”¶&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
]

SNS_DOMAINS = [
    "threads.net", "instagram.com", "line.me", "linkedin.com",
    "tiktok.com", "youtube.com", "youtu.be", "facebook.com", "x.com", "twitter.com"
]


# ==========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==========================
def is_sns_domain(url: str) -> bool:
    u = (url or "").lower()
    return any(d in u for d in SNS_DOMAINS)

def clean_url(url: str) -> str:
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)
    exclude_params = [
        "utm_source","utm_medium","utm_campaign","utm_term","utm_content",
        "fbclid","gclid","msclkid","oc","_ga","_gl"
    ]
    clean_params = {k: v for k, v in query_params.items() if k not in exclude_params}
    clean_query = urlencode(clean_params, doseq=True)
    return urlunparse(parsed._replace(query=clean_query))

def resolve_final_url(url: str, timeout: int = 3) -> str | None:
    try:
        r = requests.head(url, allow_redirects=True, timeout=timeout)
        return clean_url(r.url)
    except Exception:
        return None

def normalize_text(s: str) -> str:
    s = (s or "").lower()
    s = re.sub(r"\s+", " ", s).strip()
    return s

def signature_for_item(title: str, final_url: str) -> str:
    base = f"{normalize_text(title)}|{final_url}"
    return hashlib.md5(base.encode("utf-8")).hexdigest()

def parse_pub_date(entry) -> datetime | None:
    pub_date = None
    if hasattr(entry, "published"):
        try:
            pub_date = date_parser.parse(entry.published).astimezone(TW_TZ)
        except Exception:
            pub_date = None
    return pub_date

def safe_get_publisher(entry, final_url: str) -> str:
    # RSS source title
    try:
        if hasattr(entry, "source") and hasattr(entry.source, "title") and entry.source.title:
            return str(entry.source.title)
    except Exception:
        pass
    # domain fallback
    try:
        d = urlparse(final_url).netloc.replace("www.", "")
        return d
    except Exception:
        return "unknown"


# ==========================
# RSSåé›†
# ==========================
def process_rss_entry(entry) -> dict | None:
    rss_url = entry.get("link", "")
    title = entry.get("title", "")
    snippet = (entry.get("summary", "") or "")[:240]

    final_url = resolve_final_url(rss_url, timeout=3)
    if not final_url:
        return None
    if is_sns_domain(final_url):
        return None

    pub_date = parse_pub_date(entry)
    publisher = safe_get_publisher(entry, final_url)

    sig = signature_for_item(title, final_url)

    return {
        "title_zh": title,
        "snippet": snippet,
        "publisher": publisher,
        "published": pub_date.isoformat() if pub_date else None,
        "link": final_url,
        "signature": sig,
    }

def collect_news_parallel(max_entries_per_feed: int = 20) -> list[dict]:
    print("ğŸ“° RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ä¸­...", flush=True)
    all_entries = []

    for feed_url in RSS_FEEDS:
        try:
            feed = feedparser.parse(feed_url)
            all_entries.extend(feed.entries[:max_entries_per_feed])
        except Exception as e:
            print(f"âš ï¸ RSSåé›†ã‚¨ãƒ©ãƒ¼: {feed_url} - {e}", flush=True)

    print(f"  RSSåé›†å®Œäº†: {len(all_entries)}ä»¶", flush=True)

    items: list[dict] = []
    seen = set()

    with ThreadPoolExecutor(max_workers=10) as ex:
        futures = [ex.submit(process_rss_entry, ent) for ent in all_entries]
        for i, fut in enumerate(as_completed(futures), 1):
            if i % 100 == 0:
                print(f"  å‡¦ç†ä¸­: {i}/{len(all_entries)}ä»¶", flush=True)
            try:
                it = fut.result()
                if not it:
                    continue
                if it["signature"] in seen:
                    continue
                seen.add(it["signature"])
                items.append(it)
            except Exception:
                continue

    print(f"âœ… é‡è¤‡é™¤å¤–å¾Œ: {len(items)}ä»¶", flush=True)
    return items


# ==========================
# æ¤œç´¢ç¯„å›²ã®æ®µéšæ‹¡å¼µ
# today / weekly / monthly
# ==========================
def within_days(pub_iso: str | None, days: int) -> bool:
    if not pub_iso:
        return False
    try:
        d = datetime.fromisoformat(pub_iso)
        if d.tzinfo is None:
            d = TW_TZ.localize(d)
        return d >= (datetime.now(TW_TZ) - timedelta(days=days))
    except Exception:
        return False

def stock_keywords(stock_id: str, stock_info: dict) -> list[str]:
    kws = [stock_info.get("name",""), stock_id]
    # ã‚ˆãã‚ã‚‹è‹±å
    name = stock_info.get("name","")
    if stock_id == "2330":
        kws += ["TSMC", "å°ç©é›»", "tsmc"]
    if stock_id == "2451":
        kws += ["Transcend", "å‰µè¦‹", "transcend"]
    if stock_id == "8271":
        kws += ["Apacer", "å®‡ç»", "apacer"]
    if stock_id == "2382":
        kws += ["Quanta", "å»£é”", "quanta", "Quanta Computer"]
    # ç©ºè¦ç´ é™¤å»
    return [k for k in kws if k]

def pick_candidates_for_stock(all_news: list[dict], stock_id: str, stock_info: dict) -> list[dict]:
    kws = stock_keywords(stock_id, stock_info)

    # ã¾ãšã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ’ãƒƒãƒˆ
    candidates = []
    for n in all_news:
        text = f"{n.get('title_zh','')} {n.get('snippet','')}"
        if any(kw in text for kw in kws):
            candidates.append(n)

    # ã‚‚ã—å°‘ãªã™ãã‚‹ãªã‚‰æ¥­ç•Œãƒ¯ãƒ¼ãƒ‰ã‚‚è¨±å¯ï¼ˆè£œåŠ©ï¼‰
    if len(candidates) < 5:
        bt = (stock_info.get("business_type") or "").strip()
        if bt:
            for n in all_news:
                if n in candidates:
                    continue
                text = f"{n.get('title_zh','')} {n.get('snippet','')}"
                if bt[:6] and bt[:6] in text:
                    candidates.append(n)

    # æ—¥ä»˜ãŒæ–°ã—ã„é †
    def sort_key(n):
        p = n.get("published")
        try:
            return datetime.fromisoformat(p) if p else datetime(1970,1,1, tzinfo=TW_TZ)
        except Exception:
            return datetime(1970,1,1, tzinfo=TW_TZ)

    candidates.sort(key=sort_key, reverse=True)

    # åŒã˜ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ä¼¼ãŸã‚¿ã‚¤ãƒˆãƒ«ãŒé€£ç¶šã™ã‚‹ã®ã‚’è»½ãæŠ‘åˆ¶
    dedup = []
    seen_title = set()
    for n in candidates:
        t = normalize_text(n.get("title_zh",""))
        # ã–ã£ãã‚Šè¿‘ä¼¼ï¼ˆå…ˆé ­40æ–‡å­—ï¼‰
        key = t[:40]
        if key in seen_title:
            continue
        seen_title.add(key)
        dedup.append(n)
        if len(dedup) >= 20:
            break

    return dedup

def split_by_recency(cands: list[dict]) -> dict:
    today = [c for c in cands if within_days(c.get("published"), 1)]
    weekly = [c for c in cands if within_days(c.get("published"), 7)]
    monthly = [c for c in cands if within_days(c.get("published"), 30)]
    return {"today": today, "weekly": weekly, "monthly": monthly}


# ==========================
# Geminiï¼ˆ1éŠ˜æŸ„1å›ï¼‰ã§ã€Œæœ€é‡è¦1æœ¬ã€+ã€Œæ—¥æœ¬èªã€+ã€Œè¦ç‚¹ã€
# ==========================
def gemini_client():
    # GEMINI_API_KEY ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—ã•ã‚Œã‚‹ãŒã€æ˜ç¤ºæŒ‡å®šã‚‚å¯èƒ½
    if not GEMINI_API_KEY:
        return None
    try:
        return genai.Client(api_key=GEMINI_API_KEY)
    except Exception:
        return None

def build_gemini_prompt(stock_id: str, stock_name: str, bucket: str, items: list[dict]) -> str:
    lines = []
    for i, n in enumerate(items, 1):
        pub = n.get("published") or ""
        lines.append(
            f"[{i}] {n.get('title_zh','')}\n"
            f"å‡ºå…¸: {n.get('publisher','')}\n"
            f"æ—¥æ™‚: {pub}\n"
            f"æ¦‚è¦: {n.get('snippet','')}\n"
            f"URL: {n.get('link','')}\n"
        )

    body = "\n\n".join(lines)

    return f"""ä»¥ä¸‹ã¯å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹å€™è£œã§ã™ã€‚

ã€éŠ˜æŸ„ã€‘{stock_name}ï¼ˆ{stock_id}ï¼‰
ã€ã‚«ãƒ†ã‚´ãƒªã€‘{bucket}ï¼ˆtoday/weekly/monthlyï¼‰

ã€ç›®çš„ã€‘
- æ—¥æœ¬äººæŠ•è³‡å®¶å‘ã‘ã«ã€ŒæŠ•è³‡åˆ¤æ–­ã«æœ‰ç”¨ãªæœ€é‡è¦1æœ¬ã€ã‚’1ã¤ã ã‘é¸ã¶
- è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã‚‹ï¼ˆä¸­å›½èªåŸæ–‡ã®ä¸Šã«è¡¨ç¤ºã™ã‚‹æƒ³å®šï¼‰
- è¦ç‚¹ã‚’3ã¤ã«çµã‚‹ï¼ˆæ¨æ¸¬ã—ãªã„ã€åŸæ–‡ã®ç¯„å›²ã§ï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘â€»JSONã®ã¿ã€å‰å¾Œã«æ–‡ç« ã‚’ä»˜ã‘ãªã„
{{
  "picked_index": 1,
  "title_ja": "æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‡ªç„¶ï¼‰",
  "title_zh": "åŸæ–‡ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆãã®ã¾ã¾ï¼‰",
  "bullets": ["è¦ç‚¹1","è¦ç‚¹2","è¦ç‚¹3"],
  "why_this": "ãªãœé‡è¦ã‹ï¼ˆ1æ–‡ã€äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰"
}}

ã€æ³¨æ„ã€‘
- æ•°å€¤ã‚„äº‹å®Ÿã¯åŸæ–‡ã«åŸºã¥ã
- æ–­å®šã—ã™ããªã„ï¼ˆå¯èƒ½æ€§/è¦‹é€šã—ç­‰ã¯åŸæ–‡ãŒãã†è¿°ã¹ã‚‹å ´åˆã®ã¿ï¼‰
- 3ã€œ4è¡Œã«åã¾ã‚‹ç²’åº¦

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å€™è£œã€‘
{body}
"""

def gemini_pick_one(stock_id: str, stock_name: str, bucket: str, items: list[dict]) -> dict | None:
    client = gemini_client()
    if not client:
        return None

    prompt = build_gemini_prompt(stock_id, stock_name, bucket, items)

    try:
        resp = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt,
        )
        text = (resp.text or "").strip()
        # JSONã ã‘å–ã‚Šå‡ºã™
        m = re.search(r"\{.*\}", text, re.DOTALL)
        if not m:
            return None
        data = json.loads(m.group())
        return data
    except Exception as e:
        print(f"âš ï¸ Geminiå¤±æ•—: {stock_name} - {e}", flush=True)
        return None


# ==========================
# æŠ•è³‡åˆ¤æ–­è£œåŠ©ï¼ˆAIãªã—ãƒ»å›ºå®šï¼‰
# ==========================
def investment_aux_text(stock_name: str) -> dict:
    return {
        "title_ja": "ğŸ“‰ æŠ•è³‡åˆ¤æ–­è£œåŠ©ï¼ˆæ ªä¾¡ãƒ•ã‚§ãƒ¼ã‚ºæ•´ç†ï¼‰",
        "title_zh": "",
        "bullets": [
            "ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆææ–™ï¼‰ã®æœ‰ç„¡ã¨ã€å€¤å‹•ãã®å¤§ãã•ã¯ä¸€è‡´ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚",
            "çŸ­æœŸã®ä¸Šä¸‹ã¯â€œéœ€çµ¦/åœ°åˆã„/åˆ©ç›Šç¢ºå®šâ€ã§ã‚‚èµ·ãã‚‹ãŸã‚ã€ææ–™ã®è³ªã‚’å„ªå…ˆã—ã¦æ•´ç†ã—ã¾ã™ã€‚",
            "æœ¬ãƒ¡ãƒ¼ãƒ«ã¯å£²è²·æ¨å¥¨ã§ã¯ãªãã€ç¢ºèªã™ã¹ãè«–ç‚¹ã®æ£šå¸ã—ã§ã™ã€‚"
        ],
        "why_this": f"{stock_name}ã®å½“æ—¥æƒ…å ±ã‚’â€œç¢ºèªç”¨ã®ãƒ¡ãƒ¢â€ã¨ã—ã¦ä»˜ä¸ã—ã¦ã„ã¾ã™ã€‚",
        "link": None,
        "publisher": "System",
        "published": datetime.now(TW_TZ).isoformat(),
        "bucket": "aux",
        "is_aux": True,
    }


# ==========================
# 1éŠ˜æŸ„ã¶ã‚“çµ„ã¿ç«‹ã¦ï¼ˆæœ€ä½1æœ¬ä¿è¨¼ï¼‰
# ==========================
def build_one_stock_result(stock_id: str, stock_info: dict, all_news: list[dict]) -> dict:
    name = stock_info.get("name", stock_id)
    print("="*60, flush=True)
    print(f"ğŸ“Š {name}ï¼ˆ{stock_id}ï¼‰", flush=True)
    print("="*60, flush=True)

    cands = pick_candidates_for_stock(all_news, stock_id, stock_info)
    print(f"å€™è£œãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(cands)}ä»¶", flush=True)

    buckets = split_by_recency(cands)

    # æ¢ã™é †ï¼štoday â†’ weekly â†’ monthly â†’ ãã‚Œã§ã‚‚ãƒ€ãƒ¡ãªã‚‰ candså…ˆé ­ï¼ˆå¼·åˆ¶ï¼‰
    chosen_bucket = None
    chosen_list = None
    for b in ["today", "weekly", "monthly"]:
        if buckets[b]:
            chosen_bucket = b
            chosen_list = buckets[b]
            break

    if not chosen_list and cands:
        chosen_bucket = "monthly"
        chosen_list = cands  # å¼·åˆ¶å€™è£œï¼ˆ>30æ—¥ãŒæ··ã–ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€Œç©ºã‚ˆã‚Šãƒã‚·ã€ï¼‰
    if not chosen_list:
        # ã“ã“ã¾ã§æ¥ã‚‹ã®ã¯ç•°å¸¸ï¼ˆRSSå–ã‚Œã¦ãªã„ç­‰ï¼‰
        # ç©ºã§ã‚‚æœ€ä½1æœ¬è¦æ±‚ãªã®ã§ãƒ€ãƒŸãƒ¼ã‚’å‡ºã™
        chosen_bucket = "monthly"
        chosen_list = [{
            "title_zh": f"{name} é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆRSS/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦ç¢ºèªï¼‰",
            "snippet": "RSSå–å¾—ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ã«ã‚ˆã‚Šå€™è£œãŒ0ä»¶ã§ã—ãŸã€‚",
            "publisher": "System",
            "published": datetime.now(TW_TZ).isoformat(),
            "link": None,
            "signature": hashlib.md5(f"{stock_id}-{time.time()}".encode()).hexdigest()
        }]

    # Geminiã«æŠ•ã’ã‚‹å€™è£œã¯ä¸Šä½10ä»¶
    shortlist = chosen_list[:10]

    gem = gemini_pick_one(stock_id, name, chosen_bucket, shortlist)
    if gem:
        idx = int(gem.get("picked_index", 1)) - 1
        idx = max(0, min(idx, len(shortlist)-1))
        picked = shortlist[idx]
        news_item = {
            "title_ja": gem.get("title_ja", picked.get("title_zh", "")),
            "title_zh": gem.get("title_zh", picked.get("title_zh", "")),
            "bullets": gem.get("bullets", [])[:3],
            "why_this": gem.get("why_this", ""),
            "link": picked.get("link"),
            "publisher": picked.get("publisher"),
            "published": picked.get("published"),
            "bucket": chosen_bucket,
            "is_aux": False,
        }
        print(f"âœ… æ¡ç”¨: {chosen_bucket} / Geminié¸å®š", flush=True)
    else:
        # Geminiå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæœ€ä½å“è³ªä¿è¨¼ï¼‰
        picked = shortlist[0]
        news_item = {
            "title_ja": picked.get("title_zh", ""),  # ç¿»è¨³ã§ããªã„ã®ã§åŒæ–‡
            "title_zh": picked.get("title_zh", ""),
            "bullets": [picked.get("snippet", "")[:60] + "â€¦"],
            "why_this": "GeminiãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€å€™è£œã®å…ˆé ­ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚",
            "link": picked.get("link"),
            "publisher": picked.get("publisher"),
            "published": picked.get("published"),
            "bucket": chosen_bucket,
            "is_aux": False,
        }
        print(f"âš ï¸ æ¡ç”¨: {chosen_bucket} / Geminiæœªä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰", flush=True)

    # 1éŠ˜æŸ„ = [ãƒ‹ãƒ¥ãƒ¼ã‚¹1æœ¬] + [æŠ•è³‡åˆ¤æ–­è£œåŠ©1æœ¬]
    # â€»ã€Œå¿…ãšãƒ‹ãƒ¥ãƒ¼ã‚¹1æœ¬ã€ã®è¦ä»¶ã‚’æº€ãŸã—ã¤ã¤ã€è£œåŠ©ã¯å¸¸ã«è¿½åŠ 
    out = {
        "stock_id": stock_id,
        "stock_name": name,
        "business_type": stock_info.get("business_type", ""),
        "items": [news_item, investment_aux_text(name)],
    }
    return out


# ==========================
# ãƒ¡ãƒ¼ãƒ«é€ä¿¡
# ==========================
def send_email(render_data: list[dict], now_taipei: datetime):
    if not SENDGRID_API_KEY:
        print("âŒ SENDGRID_API_KEY ãŒæœªè¨­å®šã§ã™", flush=True)
        return
    if not EMAIL_FROM or not EMAIL_TO:
        print("âŒ EMAIL_FROM / EMAIL_TO ãŒæœªè¨­å®šã§ã™", flush=True)
        return

    from email_template_v5 import generate_html_email  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«

    html_content = generate_html_email(render_data, now_taipei, VERSION)

    to_list = [EMAIL_TO]
    cc_list = []
    if EMAIL_TO_CC:
        cc_list = [x.strip() for x in EMAIL_TO_CC.split(",") if x.strip()]

    message = Mail(
        from_email=EMAIL_FROM,
        to_emails=to_list,
        subject=f"ğŸ‡¹ğŸ‡¼ å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡ {VERSION} - {now_taipei.strftime('%Y-%m-%d %H:%M')}",
        html_content=html_content
    )
    if cc_list:
        message.add_cc(cc_list)

    try:
        sg = SendGridAPIClient(SENDGRID_API_KEY)
        resp = sg.send(message)
        print(f"âœ… ãƒ¡ãƒ¼ãƒ«é€ä¿¡æˆåŠŸï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {resp.status_code}ï¼‰", flush=True)
    except Exception as e:
        print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}", flush=True)


def main():
    print("="*60, flush=True)
    print(f"å°æ¹¾æ ªãƒ‹ãƒ¥ãƒ¼ã‚¹é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ  {VERSION}", flush=True)
    print("="*60, flush=True)

    if not STOCKS:
        print("âŒ stocks.json ã®éŠ˜æŸ„ãŒç©ºã§ã™ã€‚stocks.json ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", flush=True)
        return

    # RSSåé›†ï¼ˆåºƒã‚ã«å–ã£ã¦ã€éŠ˜æŸ„å´ã§ today/weekly/monthly ã«åˆ†é¡ï¼‰
    all_news = collect_news_parallel(max_entries_per_feed=30)

    results: list[dict] = []
    for sid, sinfo in STOCKS.items():
        results.append(build_one_stock_result(sid, sinfo, all_news))

    now_taipei = datetime.now(TW_TZ)
    print("\nğŸ“§ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ä¸­...", flush=True)
    send_email(results, now_taipei)


if __name__ == "__main__":
    main()
